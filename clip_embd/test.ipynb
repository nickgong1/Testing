{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import clip\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader,Subset\n",
    "import test_finetune\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,preprocess = clip.load(\"ViT-B/32\",device=\"cuda\")\n",
    "torch.save(model.visual.state_dict(),'zero_shot.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR100(root=\"datas\",train=True, download= True, transform=preprocess)\n",
    "test_data = datasets.CIFAR100(root = \"datas\", train= False, download=True, transform=preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datas/cifar-100-python/train', 'rb') as fo:\n",
    "    dict = pickle.load(fo, encoding='bytes')\n",
    "\n",
    "with open('datas/cifar-100-python/test', 'rb') as fo:\n",
    "    dict_test = pickle.load(fo, encoding='bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_all(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = dict[b'fine_labels']\n",
    "label_test = dict_test[b'fine_labels']\n",
    "\n",
    "task1_keys = list(range(20))\n",
    "task2_keys = list(range(20,40))\n",
    "task3_keys= list(range(40,60))\n",
    "task4_keys = list(range(60,80))\n",
    "task5_keys = list(range(80,100))\n",
    "\n",
    "task1_indicies= []\n",
    "task2_indicies= []\n",
    "task3_indicies= []\n",
    "task4_indicies= []\n",
    "task5_indicies= []\n",
    "\n",
    "test1_indicies= []\n",
    "test2_indicies= []\n",
    "test3_indicies= []\n",
    "test4_indicies= []\n",
    "test5_indicies= []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] in task1_keys:\n",
    "        task1_indicies.append(i)\n",
    "    elif labels[i] in task2_keys:\n",
    "        task2_indicies.append(i)\n",
    "    elif labels[i] in task3_keys:\n",
    "        task3_indicies.append(i) \n",
    "    elif labels[i] in task4_keys:\n",
    "        task4_indicies.append(i)\n",
    "    else:\n",
    "        task5_indicies.append(i)\n",
    "\n",
    "\n",
    "for i in range(len(label_test)):\n",
    "    if label_test[i] in task1_keys:\n",
    "        test1_indicies.append(i)\n",
    "    elif label_test[i] in task2_keys:\n",
    "        test2_indicies.append(i)\n",
    "    elif label_test[i] in task3_keys:\n",
    "        test3_indicies.append(i) \n",
    "    elif label_test[i] in task4_keys:\n",
    "        test4_indicies.append(i)\n",
    "    else:\n",
    "        test5_indicies.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task1 = Subset(train_data,task1_indicies)\n",
    "task2 = Subset(train_data,task2_indicies)\n",
    "task3 = Subset(train_data,task3_indicies)\n",
    "task4 = Subset(train_data,task4_indicies)\n",
    "task5 = Subset(train_data,task5_indicies)\n",
    "\n",
    "\n",
    "test1 = Subset(test_data,test1_indicies)\n",
    "test2 = Subset(test_data,test2_indicies)\n",
    "test3 = Subset(test_data,test3_indicies)\n",
    "test4 = Subset(test_data,test4_indicies)\n",
    "test5 = Subset(test_data,test5_indicies)\n",
    "test = [test1, test2, test3, test4, test5]\n",
    "\n",
    "loader1 = DataLoader(task1, 64, shuffle=True)\n",
    "loader2 = DataLoader(task2, 64, shuffle=True)\n",
    "loader3 = DataLoader(task3, 64, shuffle=True)\n",
    "loader4 = DataLoader(task4, 64, shuffle=True)\n",
    "loader5 = DataLoader(task5, 64, shuffle=True)\n",
    "train = [loader1, loader2, loader3, loader4, loader5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_sample( testdata, num, seeds):\n",
    "    random.seed(seeds)\n",
    "\n",
    "    id = random.sample(range(0,len(testdata)), num)\n",
    "\n",
    "    shape_exp,_ = test_data[0]\n",
    "    shape_exp = list(shape_exp.shape)\n",
    "    shape_exp.insert(0,num)\n",
    "\n",
    "    sample = torch.zeros(shape_exp)\n",
    "    label = torch.zeros(num)\n",
    "\n",
    "    for i in range(num):\n",
    "        d, l = testdata[id[i]]\n",
    "        sample[i] = d\n",
    "        label[i] = l\n",
    "    \n",
    "    sample = sample.cuda()\n",
    "    label = label.cuda()\n",
    "\n",
    "    return sample, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb(model, dict, img ,label, txt_only):\n",
    "    ref_img_emb = None\n",
    "    \n",
    "    if txt_only == False:\n",
    "        ref_img_emb = model.encode_image(img)\n",
    "        ref_img_emb = ref_img_emb / ref_img_emb.norm(dim=-1, keepdim=True)\n",
    "    label  =label.int()\n",
    "    dict_ = [dict[i] for i in label]\n",
    "    ref_txt_emb = torch.cat([clip.tokenize(f\"the image of a {c}\") for c in dict_]).cuda()\n",
    "    ref_txt_emb = model.encode_text(ref_txt_emb)\n",
    "    ref_txt_emb = ref_txt_emb/ ref_txt_emb.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return ref_img_emb, ref_txt_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = test_finetune.Finetune(train_data.classes, 2, model)\n",
    "\n",
    "TABLE = [100,80,60,30,10]\n",
    "TEST = torch.cat([clip.tokenize(f\"the image of a {c}\") for c in test_data.classes]).cuda()\n",
    "INTERPO = [0.3,0.3,0.4]\n",
    "\n",
    "num_ref_sample = 1000\n",
    "\n",
    "def sub_test(cls_idx, model, test = TEST):\n",
    "    sub = TEST[:(cls_idx+1)*20]\n",
    "    out = model.encode_text(sub)\n",
    "    out = out/out.norm(dim=-1, keepdim=True)\n",
    "    return out\n",
    "\n",
    "for count in range(5):\n",
    "    print(f\"Begin training task {count}...\")\n",
    "    f.fine_tune(train[count])\n",
    "\n",
    "    ########################################################################\n",
    "    # This is for weight-ensemble\n",
    "    ########################################################################\n",
    "    # if os.path.exists(\"previous.pt\"):\n",
    "    #     previous_state = torch.load(\"previous.pt\")\n",
    "    #     current = model.visual.state_dict()\n",
    "    #     zero_shot = torch.load(\"zero_shot.pt\")\n",
    "\n",
    "    #     interpolated = {}\n",
    "    #     for key in current :\n",
    "    #         # interpolated[key] = INTERPO[0] * zero_shot[key] + INTERPO[1] * previous_state[key] + INTERPO[2] * current[key]\n",
    "    #         # interpolated[key] = 0.5 * zero_shot[key] + 0.5 * current[key]\n",
    "    #         interpolated[key] = 0.5 * previous_state[key] + 0.5 * current[key]\n",
    "        \n",
    "    #     model.visual.load_state_dict(interpolated)\n",
    "    #     torch.save(interpolated, \"previous.pt\")\n",
    "    # else:\n",
    "    #     torch.save(model.visual.state_dict(), \"previous.pt\")\n",
    "    ########################################################################\n",
    "\n",
    "    ref_img, ref_label = get_ref_sample(test[count],10,count)\n",
    "    ref_img, ref_txt = get_emb(model, test_data.classes,ref_img, ref_label, False)\n",
    "    test_loader = DataLoader(test[count], 64, shuffle=False)\n",
    "    txt_out = sub_test(count, model)\n",
    "    print(\"Testing current task...\")\n",
    "    acc = 0\n",
    "    total_len = 0\n",
    "    for data, label in tqdm(test_loader):\n",
    "        data = data.cuda()\n",
    "        label = label.cuda()\n",
    "        out = model.encode_image(data)\n",
    "        out = out/out.norm(dim=-1, keepdim=True)\n",
    "        sim = out @ txt_out.T\n",
    "        ans = torch.argmax(sim, 1)\n",
    "        r = (ans == label).sum()\n",
    "        total_len += len(data)\n",
    "        acc += r\n",
    "    \n",
    "    acc = acc/total_len\n",
    "    print(f\"Accuracy for current task is {acc}\")\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "# This part is for normal testing with test datasets\n",
    "##############################################################################################\n",
    "    acc = 0\n",
    "    total_len = 0\n",
    "    for test_count in range(count):\n",
    "        print(f\"Testing task {test_count}...\" )\n",
    "        test_loader = DataLoader(test[test_count], 64, shuffle=False)\n",
    "        for data, label in tqdm(test_loader):\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "            out = model.encode_image(data)\n",
    "            out = out/out.norm(dim=-1, keepdim = True)\n",
    "            sim = out @ txt_out.T\n",
    "            ans = torch.argmax(sim, dim = 1)\n",
    "            r = (ans == label).sum()\n",
    "            total_len += len(data)\n",
    "            acc += r\n",
    "        acc = acc/total_len\n",
    "        print(f\"Accuracy for task {test_count} is {acc}\")\n",
    "###############################################################################################\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "# This is testing the \"CLIP embedding superposition\"\n",
    "###############################################################################################\n",
    "    # for test_count in range(count):\n",
    "    #     print(f\"Testing task {test_count}...\" )\n",
    "    #     img, label = get_ref_sample(test[test_count], num_ref_sample, test_count)\n",
    "    #     _, txt = get_emb(model, test_data.classes, None, label, True)\n",
    "    #     point = 0\n",
    "    #     for i in tqdm(range(num_ref_sample)):\n",
    "    #         sample = txt[i].unsqueeze(0)\n",
    "    #         guess_img = ref_img - ref_txt + sample\n",
    "    #         guess_img = torch.mean(guess_img, dim = 0)\n",
    "    #         similarity = guess_img @ txt_out.T\n",
    "    #         _, result = torch.topk(similarity, 5)\n",
    "    #         temp = (result == label[i]).nonzero(as_tuple=True)[0]\n",
    "    #         if temp.size() != 0:\n",
    "    #             point += TABLE[temp[0]]/num_ref_sample\n",
    "    #     print(f\"The test score for task {test_count} is {point}\")\n",
    "################################################################################################\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
